{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "1265f1a16f12b26e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "4103dcd30135301"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.047974Z",
     "start_time": "2025-08-06T12:27:26.042706Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.__00__paths import spectrogram_train_dir, test_dir, validation_dir, model_dir\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device Setup",
   "id": "4fe250fe7e9f6a15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.119532Z",
     "start_time": "2025-08-06T12:27:26.117358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "id": "5f996d9b3701272e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Definition",
   "id": "b3daeeca37df1b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.146781Z",
     "start_time": "2025-08-06T12:27:26.143217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GenreSpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {genre.name: idx for idx, genre in enumerate(sorted(self.root_dir.iterdir()))}\n",
    "\n",
    "        for genre in self.class_to_idx:\n",
    "            for file in (self.root_dir / genre).glob(\"*.png\"):\n",
    "                self.samples.append((file, self.class_to_idx[genre]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.samples[idx]\n",
    "        image = Image.open(image_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "id": "139986d7c3828b4f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transfroms & DataLoaders",
   "id": "c8f622097ab23b3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.167633Z",
     "start_time": "2025-08-06T12:27:26.161490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Declare Transformation to be done in Data setup\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL.Image -> PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # X_norm = (x - 0.5) / (0.5) = 2x - 1\n",
    "])\n",
    "\n",
    "train_data = GenreSpectrogramDataset(spectrogram_train_dir, transform=transform)\n",
    "validation_data = GenreSpectrogramDataset(validation_dir, transform=transform)\n",
    "\n",
    "# Load Data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=True)"
   ],
   "id": "3d98bf78acc883ce",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Channel Attention",
   "id": "aba995be75300eed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.177911Z",
     "start_time": "2025-08-06T12:27:26.174947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = y.squeeze(-1).transpose(-1, -2)\n",
    "        y = self.conv(y)\n",
    "        y = self.sigmoid(y).transpose(-1, -2).unsqueeze(-1)\n",
    "        return x * y.expand_as(x)\n"
   ],
   "id": "f64db11d2547663e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.192824Z",
     "start_time": "2025-08-06T12:27:26.189126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Genre_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(in_c, out_c, drop):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(),\n",
    "                ChannelAttention(out_c),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(drop)\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            block(1, 32, 0.25),\n",
    "            block(32, 64, 0.25),\n",
    "            block(64, 128, 0.3),\n",
    "            block(128, 256, 0.3),\n",
    "            block(256, 512, 0.4)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.classifier(x)"
   ],
   "id": "278176c4852a64f6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init Model, Optimizer, Loss",
   "id": "c30b52557839fa8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.325310Z",
     "start_time": "2025-08-06T12:27:26.199992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Genre_CNN(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "4b0fc94a2419ee83",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Function",
   "id": "e6dc9ad0d5a49829"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.333667Z",
     "start_time": "2025-08-06T12:27:26.331385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ],
   "id": "462c5fdaac604343",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validation Function",
   "id": "dcebd55f475f1fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:27:26.340633Z",
     "start_time": "2025-08-06T12:27:26.338528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ],
   "id": "7496c918ded834ea",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Loop",
   "id": "f5d9c8d832e520ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:28:17.676247Z",
     "start_time": "2025-08-06T12:27:26.348389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, validation_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1:02d}: \"\n",
    "          f\"Train Loss={train_loss:.4f} Acc={train_acc:.4f} | \"\n",
    "          f\"Val Loss={val_loss:.4f} Acc={val_acc:.4f}\")"
   ],
   "id": "c35989b9112ab967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.2573 Acc=0.1545 | Val Loss=2.3126 Acc=0.1000\n",
      "Epoch 02: Train Loss=2.1295 Acc=0.2546 | Val Loss=2.2961 Acc=0.1467\n",
      "Epoch 03: Train Loss=1.9841 Acc=0.3090 | Val Loss=2.2263 Acc=0.1533\n",
      "Epoch 04: Train Loss=1.9096 Acc=0.3033 | Val Loss=2.2141 Acc=0.1600\n",
      "Epoch 05: Train Loss=1.8401 Acc=0.3076 | Val Loss=2.2819 Acc=0.1467\n",
      "Epoch 06: Train Loss=1.7949 Acc=0.3505 | Val Loss=2.3920 Acc=0.1533\n",
      "Epoch 07: Train Loss=1.7500 Acc=0.3562 | Val Loss=2.4447 Acc=0.1533\n",
      "Epoch 08: Train Loss=1.7005 Acc=0.3720 | Val Loss=2.7508 Acc=0.1400\n",
      "Epoch 09: Train Loss=1.6704 Acc=0.3863 | Val Loss=2.8386 Acc=0.1333\n",
      "Epoch 10: Train Loss=1.6440 Acc=0.4134 | Val Loss=2.8241 Acc=0.1333\n",
      "Epoch 11: Train Loss=1.6028 Acc=0.4192 | Val Loss=2.9823 Acc=0.1467\n",
      "Epoch 12: Train Loss=1.5565 Acc=0.4134 | Val Loss=2.9548 Acc=0.1200\n",
      "Epoch 13: Train Loss=1.5091 Acc=0.4721 | Val Loss=3.1016 Acc=0.1200\n",
      "Epoch 14: Train Loss=1.4996 Acc=0.4750 | Val Loss=2.6914 Acc=0.1533\n",
      "Epoch 15: Train Loss=1.4597 Acc=0.4950 | Val Loss=2.7631 Acc=0.1400\n",
      "Epoch 16: Train Loss=1.4130 Acc=0.4936 | Val Loss=2.6882 Acc=0.1200\n",
      "Epoch 17: Train Loss=1.3973 Acc=0.5079 | Val Loss=2.2962 Acc=0.1600\n",
      "Epoch 18: Train Loss=1.4062 Acc=0.5036 | Val Loss=2.5077 Acc=0.1600\n",
      "Epoch 19: Train Loss=1.3414 Acc=0.5279 | Val Loss=2.2721 Acc=0.1533\n",
      "Epoch 20: Train Loss=1.3463 Acc=0.5250 | Val Loss=2.3760 Acc=0.1533\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save Model",
   "id": "179d544ff560d7fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:28:27.200301Z",
     "start_time": "2025-08-06T12:28:27.009622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = model_dir / \"genre_cnn_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"✔️ Model saved at {'/'.join(model_path.parts[-3:])}.\")"
   ],
   "id": "9d03e148abeb8e73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Model saved at outputs/models/genre_cnn_model.pth.\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
