{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "1265f1a16f12b26e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "4103dcd30135301"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.292846Z",
     "start_time": "2025-08-08T16:19:51.978135Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.__00__paths import spectrogram_train_dir, spectrogram_validation_dir, model_dir\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device Setup",
   "id": "4fe250fe7e9f6a15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.317279Z",
     "start_time": "2025-08-08T16:19:55.296901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "id": "5f996d9b3701272e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Definition",
   "id": "b3daeeca37df1b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.322617Z",
     "start_time": "2025-08-08T16:19:55.320087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GenreSpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {genre.name: idx for idx, genre in enumerate(sorted(self.root_dir.iterdir()))}\n",
    "\n",
    "        for genre in self.class_to_idx:\n",
    "            for file in (self.root_dir / genre).glob(\"*.png\"):\n",
    "                self.samples.append((file, self.class_to_idx[genre]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.samples[idx]\n",
    "        image = Image.open(image_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "id": "139986d7c3828b4f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transfroms & DataLoaders",
   "id": "c8f622097ab23b3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.330848Z",
     "start_time": "2025-08-08T16:19:55.325807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Declare Transformation to be done in Data setup\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL.Image -> PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # X_norm = (x - 0.5) / (0.5) = 2x - 1\n",
    "])\n",
    "\n",
    "train_data = GenreSpectrogramDataset(spectrogram_train_dir, transform=transform)\n",
    "validation_data = GenreSpectrogramDataset(spectrogram_validation_dir, transform=transform)\n",
    "\n",
    "# Load Data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=True)"
   ],
   "id": "3d98bf78acc883ce",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Channel Attention",
   "id": "aba995be75300eed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.335594Z",
     "start_time": "2025-08-08T16:19:55.333668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = y.squeeze(-1).transpose(-1, -2)\n",
    "        y = self.conv(y)\n",
    "        y = self.sigmoid(y).transpose(-1, -2).unsqueeze(-1)\n",
    "        return x * y.expand_as(x)\n"
   ],
   "id": "f64db11d2547663e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.340582Z",
     "start_time": "2025-08-08T16:19:55.338156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Genre_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(in_c, out_c, drop):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(),\n",
    "                ChannelAttention(out_c),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(drop)\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            block(1, 32, 0.25),\n",
    "            block(32, 64, 0.25),\n",
    "            block(64, 128, 0.3),\n",
    "            block(128, 256, 0.3),\n",
    "            block(256, 512, 0.4)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.classifier(x)"
   ],
   "id": "278176c4852a64f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init Model, Optimizer, Loss",
   "id": "c30b52557839fa8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.410739Z",
     "start_time": "2025-08-08T16:19:55.342620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Genre_CNN(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "4b0fc94a2419ee83",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Function",
   "id": "e6dc9ad0d5a49829"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.417592Z",
     "start_time": "2025-08-08T16:19:55.415418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ],
   "id": "462c5fdaac604343",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validation Function",
   "id": "dcebd55f475f1fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:19:55.421438Z",
     "start_time": "2025-08-08T16:19:55.419641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ],
   "id": "7496c918ded834ea",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Loop",
   "id": "f5d9c8d832e520ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:20:52.651396Z",
     "start_time": "2025-08-08T16:19:55.424411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, validation_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1:02d}: \"\n",
    "          f\"Train Loss={train_loss:.4f} Acc={train_acc:.4f} | \"\n",
    "          f\"Val Loss={val_loss:.4f} Acc={val_acc:.4f}\")"
   ],
   "id": "c35989b9112ab967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.2436 Acc=0.1845 | Val Loss=2.3047 Acc=0.1000\n",
      "Epoch 02: Train Loss=2.1019 Acc=0.2604 | Val Loss=2.2946 Acc=0.1000\n",
      "Epoch 03: Train Loss=1.9945 Acc=0.3004 | Val Loss=2.2769 Acc=0.1267\n",
      "Epoch 04: Train Loss=1.9481 Acc=0.3047 | Val Loss=2.2912 Acc=0.1733\n",
      "Epoch 05: Train Loss=1.8544 Acc=0.3534 | Val Loss=2.3370 Acc=0.1867\n",
      "Epoch 06: Train Loss=1.7931 Acc=0.3820 | Val Loss=2.3758 Acc=0.1867\n",
      "Epoch 07: Train Loss=1.7302 Acc=0.3734 | Val Loss=2.4437 Acc=0.1867\n",
      "Epoch 08: Train Loss=1.6914 Acc=0.4120 | Val Loss=2.4550 Acc=0.1933\n",
      "Epoch 09: Train Loss=1.6581 Acc=0.4034 | Val Loss=2.5672 Acc=0.1933\n",
      "Epoch 10: Train Loss=1.5922 Acc=0.4263 | Val Loss=2.6645 Acc=0.1867\n",
      "Epoch 11: Train Loss=1.5662 Acc=0.4363 | Val Loss=2.6469 Acc=0.1933\n",
      "Epoch 12: Train Loss=1.5342 Acc=0.4478 | Val Loss=2.5860 Acc=0.2000\n",
      "Epoch 13: Train Loss=1.4797 Acc=0.4692 | Val Loss=2.7262 Acc=0.2000\n",
      "Epoch 14: Train Loss=1.4394 Acc=0.4850 | Val Loss=2.5356 Acc=0.2333\n",
      "Epoch 15: Train Loss=1.4600 Acc=0.4721 | Val Loss=2.8067 Acc=0.1867\n",
      "Epoch 16: Train Loss=1.4343 Acc=0.5036 | Val Loss=2.7200 Acc=0.2333\n",
      "Epoch 17: Train Loss=1.3745 Acc=0.5279 | Val Loss=2.6443 Acc=0.2267\n",
      "Epoch 18: Train Loss=1.3750 Acc=0.5207 | Val Loss=2.6094 Acc=0.2533\n",
      "Epoch 19: Train Loss=1.3513 Acc=0.5222 | Val Loss=2.5705 Acc=0.2467\n",
      "Epoch 20: Train Loss=1.3389 Acc=0.5579 | Val Loss=2.7204 Acc=0.2667\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save Model",
   "id": "179d544ff560d7fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T16:20:52.725168Z",
     "start_time": "2025-08-08T16:20:52.700727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = model_dir / \"genre_cnn_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"✔️ Model saved at {'/'.join(model_path.parts[-3:])}.\")"
   ],
   "id": "9d03e148abeb8e73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Model saved at outputs/models/genre_cnn_model.pth.\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
