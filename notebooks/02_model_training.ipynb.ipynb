{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "1265f1a16f12b26e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "4103dcd30135301"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T13:24:21.254371Z",
     "start_time": "2025-08-05T13:24:21.250145Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.__00__paths import train_dir, test_dir, validation_dir, model_dir\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device Setup",
   "id": "4fe250fe7e9f6a15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:50.060987Z",
     "start_time": "2025-08-05T13:18:50.056291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "id": "5f996d9b3701272e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Definition",
   "id": "b3daeeca37df1b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:53.647127Z",
     "start_time": "2025-08-05T13:18:53.640465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GenreSpectrogramDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {genre.name: idx for idx, genre in enumerate(sorted(self.root_dir.iterdir()))}\n",
    "\n",
    "        for genre in self.class_to_idx:\n",
    "            for file in (self.root_dir / genre).glob(\"*.png\"):\n",
    "                self.samples.append((file, self.class_to_idx[genre]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.samples[idx]\n",
    "        image = Image.open(image_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "id": "139986d7c3828b4f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transfroms & DataLoaders",
   "id": "c8f622097ab23b3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:54.849824Z",
     "start_time": "2025-08-05T13:18:54.831172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Declare Transformation to be done in Data setup\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL.Image -> PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # X_norm = (x - 0.5) / (0.5) = 2x - 1\n",
    "])\n",
    "\n",
    "train_data = GenreSpectrogramDataset(train_dir, transform=transform)\n",
    "validation_data = GenreSpectrogramDataset(validation_dir, transform=transform)\n",
    "\n",
    "# Load Data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=True)"
   ],
   "id": "3d98bf78acc883ce",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Channel Attention",
   "id": "aba995be75300eed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:56.030397Z",
     "start_time": "2025-08-05T13:18:56.027146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = y.squeeze(-1).transpose(-1, -2)\n",
    "        y = self.conv(y)\n",
    "        y = self.sigmoid(y).transpose(-1, -2).unsqueeze(-1)\n",
    "        return x * y.expand_as(x)\n"
   ],
   "id": "f64db11d2547663e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:56.580644Z",
     "start_time": "2025-08-05T13:18:56.573821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Genre_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(in_c, out_c, drop):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(),\n",
    "                ChannelAttention(out_c),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(drop)\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            block(1, 32, 0.25),\n",
    "            block(32, 64, 0.25),\n",
    "            block(64, 128, 0.3),\n",
    "            block(128, 256, 0.3),\n",
    "            block(256, 512, 0.4)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.classifier(x)"
   ],
   "id": "278176c4852a64f6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init Model, Optimizer, Loss",
   "id": "c30b52557839fa8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:18:58.405065Z",
     "start_time": "2025-08-05T13:18:58.358535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Genre_CNN(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "4b0fc94a2419ee83",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Function",
   "id": "e6dc9ad0d5a49829"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:19:00.852856Z",
     "start_time": "2025-08-05T13:19:00.846905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ],
   "id": "462c5fdaac604343",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validation Function",
   "id": "dcebd55f475f1fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:19:04.157711Z",
     "start_time": "2025-08-05T13:19:04.152539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ],
   "id": "7496c918ded834ea",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Loop",
   "id": "f5d9c8d832e520ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:20:34.270572Z",
     "start_time": "2025-08-05T13:19:08.272626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, validation_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1:02d}: \"\n",
    "          f\"Train Loss={train_loss:.4f} Acc={train_acc:.4f} | \"\n",
    "          f\"Val Loss={val_loss:.4f} Acc={val_acc:.4f}\")"
   ],
   "id": "c35989b9112ab967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=2.2272 Acc=0.2082 | Val Loss=2.0991 Acc=0.0781\n",
      "Epoch 02: Train Loss=2.0256 Acc=0.2803 | Val Loss=2.2431 Acc=0.0372\n",
      "Epoch 03: Train Loss=1.8877 Acc=0.3363 | Val Loss=2.3723 Acc=0.0706\n",
      "Epoch 04: Train Loss=1.7887 Acc=0.3864 | Val Loss=2.5178 Acc=0.0725\n",
      "Epoch 05: Train Loss=1.6795 Acc=0.4394 | Val Loss=2.7851 Acc=0.0781\n",
      "Epoch 06: Train Loss=1.6237 Acc=0.4274 | Val Loss=2.8841 Acc=0.0762\n",
      "Epoch 07: Train Loss=1.5730 Acc=0.4494 | Val Loss=2.8494 Acc=0.1041\n",
      "Epoch 08: Train Loss=1.5096 Acc=0.4755 | Val Loss=3.2117 Acc=0.0948\n",
      "Epoch 09: Train Loss=1.4859 Acc=0.4775 | Val Loss=2.9637 Acc=0.1078\n",
      "Epoch 10: Train Loss=1.4546 Acc=0.4855 | Val Loss=2.9826 Acc=0.1413\n",
      "Epoch 11: Train Loss=1.4218 Acc=0.5145 | Val Loss=3.0738 Acc=0.1190\n",
      "Epoch 12: Train Loss=1.3905 Acc=0.5085 | Val Loss=2.8982 Acc=0.1431\n",
      "Epoch 13: Train Loss=1.3919 Acc=0.5035 | Val Loss=3.2243 Acc=0.1301\n",
      "Epoch 14: Train Loss=1.3436 Acc=0.5385 | Val Loss=3.2017 Acc=0.1431\n",
      "Epoch 15: Train Loss=1.2993 Acc=0.5666 | Val Loss=3.4323 Acc=0.1431\n",
      "Epoch 16: Train Loss=1.2703 Acc=0.5596 | Val Loss=3.2435 Acc=0.1115\n",
      "Epoch 17: Train Loss=1.2593 Acc=0.5506 | Val Loss=3.2610 Acc=0.1115\n",
      "Epoch 18: Train Loss=1.2492 Acc=0.5756 | Val Loss=3.3319 Acc=0.1115\n",
      "Epoch 19: Train Loss=1.1855 Acc=0.6026 | Val Loss=3.5026 Acc=0.1134\n",
      "Epoch 20: Train Loss=1.1623 Acc=0.5966 | Val Loss=3.5884 Acc=0.1097\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save Model",
   "id": "179d544ff560d7fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:24:59.343094Z",
     "start_time": "2025-08-05T13:24:59.304595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), model_dir / \"genre_cnn_model.pth\")\n",
    "print(f\"Model saved at {'/'.join((model_dir / \"genre_cnn_model.pth\"))}.\")"
   ],
   "id": "9d03e148abeb8e73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at outputs/models/genre_cnn_model.pth.\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
